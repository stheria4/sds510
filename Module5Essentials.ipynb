{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJXrQ3vua7eHvR6b+rQMvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stheria4/sds510/blob/master/Module5Essentials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jeopardy Classifier (Naive Bayes, Logistic Regression, SVM)\n",
        "**Name:** Sean Theriault\n",
        "**Student ID:** stheria4\n",
        "**Course:** SDS 510 – Python for Data Wrangling  \n",
        "**Date:** 11/19/2025\n",
        "**Project:** Module 5 - Essentials Badge"
      ],
      "metadata": {
        "id": "JFY2FPHhIKFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more comments to the assignment as requested in my previous module feedback"
      ],
      "metadata": {
        "id": "Y1eMVXUZ3bA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script imports the necessary libraries."
      ],
      "metadata": {
        "id": "3kru33LamPtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2CXs83NBk9Kt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset from sharable google drive link"
      ],
      "metadata": {
        "id": "F5QsHVGURM91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "url = \"https://drive.google.com/uc?export=download&id=1DCMBbMHAtGNnAZi2H8iupc429HSlDhgZ\"\n",
        "df = pd.read_json(url)"
      ],
      "metadata": {
        "id": "U3jUzzbuF11K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Data Setup\n",
        "\n",
        "Here I converted the money values into regular numbers so I could label each question as high-value or low-value. Then I used the raw question text and turned it into simple bag-of-words features. After that, I split the data into training and testing sets for the classifiers."
      ],
      "metadata": {
        "id": "qn99BzUX1KUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as Basics Module\n",
        "def to_num(v):\n",
        "    if isinstance(v, str):\n",
        "        v = v.replace(\"$\", \"\").replace(\",\", \"\")\n",
        "        try:\n",
        "            return int(v)\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "df[\"ValueNum\"] = df[\"value\"].apply(to_num)\n",
        "df = df.dropna(subset=[\"ValueNum\"])\n",
        "\n",
        "# Make binary labels\n",
        "df[\"Label\"] = df[\"ValueNum\"].apply(lambda x: 1 if x >= 1000 else 0)\n",
        "\n",
        "# Use raw question text (cleaning kept causing issues earlier)\n",
        "texts = df[\"question\"].fillna(\"\").astype(str)\n",
        "\n",
        "\n",
        "# Vectorize using simple bag-of-words\n",
        "vec = CountVectorizer()\n",
        "X = vec.fit_transform(texts)\n",
        "y = df[\"Label\"]\n",
        "\n",
        "# Train/test split (just using the typical 20% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1\n",
        ")"
      ],
      "metadata": {
        "id": "c4PlnoiG0qU3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Approach (Baseline)\n",
        "\n",
        "This is the first basic classifier I tried. It uses the question text with a bag-of-words model. Naive Bayes is simple and usually works okay for text, so I used it as my starting point."
      ],
      "metadata": {
        "id": "D17uds4eQ17V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = MultinomialNB()\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "pred1 = model1.predict(X_test)\n",
        "# Check Accuracy\n",
        "acc1 = accuracy_score(y_test, pred1)\n",
        "\n",
        "print(\"Approach 1 (Naive Bayes) Accuracy:\", acc1)"
      ],
      "metadata": {
        "id": "pXT3OvASAtx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7837b17-7482-4951-b601-0f4b83cd0b3b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approach 1 (Naive Bayes) Accuracy: 0.690084388185654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Approach\n",
        "\n",
        "For the second method, I tried Logistic Regression. It uses the same vectorized text but a different type of classifier. I wanted to see if a more “linear” model would do better or worse than Naive Bayes."
      ],
      "metadata": {
        "id": "EU4Bt8mVzl6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying Logistic Regression as a second method.\n",
        "# Using max_iter=200 so the Logistic Regression model actually finishes training.\n",
        "model2 = LogisticRegression(max_iter=200)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Seeing how well it predicts the labels.\n",
        "pred2 = model2.predict(X_test)\n",
        "# Check accuracy\n",
        "acc2 = accuracy_score(y_test, pred2)\n",
        "\n",
        "print(\"Approach 2 (Logistic Regression) Accuracy:\", acc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UChdymJky8Ql",
        "outputId": "d1409bda-9892-4730-e57b-a0338abacd40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approach 2 (Logistic Regression) Accuracy: 0.6971167369901548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear SVM (LinearSVC) Approach\n",
        "\n",
        "For this approach, I tested a Linear Support Vector Machine. This is another common text-classification method. I didn’t change much else—same data, same vectorization—just swapped in the SVM model to compare results."
      ],
      "metadata": {
        "id": "izxjAFXCz1wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I kept having the SVM freeze, so I looked this up on StackOverflow.\n",
        "# People said to use dual=False for text data, so I added that to make it train faster.\n",
        "model3 = LinearSVC(dual=False)\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "pred3 = model3.predict(X_test)\n",
        "# Check accuracy\n",
        "acc3 = accuracy_score(y_test, pred3)\n",
        "\n",
        "print(\"Approach 3 (BOW + SVM) Accuracy:\", acc3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf85xoY1zW1U",
        "outputId": "89495de1-bc8f-4750-aa13-ec4e92c5d0ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approach 3 (BOW + SVM) Accuracy: 0.673300515705579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write Output results to a txt file"
      ],
      "metadata": {
        "id": "QV4yFKLW1zS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE OUTPUT RESULTS\n",
        "with open(\"classification_results.txt\", \"w\") as f:\n",
        "    f.write(\"Approach 1 (Naive Bayes) Accuracy: \" + str(acc1) + \"\\n\")\n",
        "    f.write(\"Approach 2 (Logistic Regression) Accuracy: \" + str(acc2) + \"\\n\")\n",
        "    f.write(\"Approach 3 (SVM) Accuracy: \" + str(acc3) + \"\\n\")\n",
        "\n",
        "print(\"\\nSaved classification_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67PnZSPX1xb3",
        "outputId": "115c9754-1829-4097-93f2-a5665c89ae94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved classification_results.txt\n"
          ]
        }
      ]
    }
  ]
}